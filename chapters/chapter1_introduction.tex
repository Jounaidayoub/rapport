% Chapter 1: Introduction
\chapter{Introduction}

\section{General Context}

The financial markets operate in an increasingly complex and volatile environment where price movements can occur within microseconds. The importance of real-time financial surveillance has grown exponentially with the rise of algorithmic trading, high-frequency trading, and the democratization of financial markets through retail trading platforms.

Modern financial institutions and regulatory bodies require sophisticated systems capable of monitoring thousands of financial instruments simultaneously, detecting anomalous price movements, and generating alerts in real-time. These systems must process massive volumes of data while maintaining low latency and high accuracy to prevent market manipulation, detect insider trading, and ensure market integrity.

The evolution of data processing technologies, particularly in the areas of stream processing, distributed computing, and machine learning, has opened new possibilities for creating more efficient and accurate surveillance systems. Technologies such as Apache Kafka for real-time data streaming, Elasticsearch for fast search and analytics, and modern frameworks like FastAPI for building high-performance APIs have revolutionized how financial data can be processed and analyzed.

\section{Problem Statement}

Financial markets generate enormous amounts of data every second, with price updates, trading volumes, and market events occurring continuously across multiple exchanges and trading venues. Traditional surveillance systems often struggle with several key challenges:
% \include{chapters/cover.tex}
\begin{itemize}
    \item \textbf{Real-time Processing}: The need to process and analyze financial data in real-time to detect anomalies as they occur, rather than discovering them hours or days later.
    
    \item \textbf{Scalability}: The ability to handle increasing volumes of data as more financial instruments are monitored and as market activity grows.
        
    \item \textbf{Historical Analysis}: Maintaining comprehensive historical records for post-mortem analysis, regulatory compliance, and pattern recognition.
    
    \item \textbf{Alert Management}: Providing timely and actionable alerts to the appropriate stakeholders when anomalies are detected.
\end{itemize}

The challenge lies in building a system that can address all these requirements simultaneously while remaining cost-effective and maintainable.
\section{Requirements}

To address the challenges outlined in the problem statement, the proposed system must satisfy a set of functional and non-functional requirements.

\subsection{Functional Requirements}
Functional requirements define the specific behaviors and capabilities of the system. For this financial surveillance system, these include:
\begin{itemize}
    \item \textbf{Data Ingestion}: The system must be able to ingest real-time financial data from various sources, including market data feeds and trading platforms.
    \item \textbf{Anomaly Detection}: The system must implement algorithms to detect various types of anomalies, such as unusual price movements, abnormal trading volumes, and deviations from historical patterns.
    \item \textbf{Alerting Mechanism}: Upon detection of an anomaly, the system must generate and deliver timely alerts to designated users or systems through multiple channels (e.g., via Kafka topics, Email, ...).
    \item \textbf{Data Storage and Retrieval}: The system must store historical financial data and detected anomalies for auditing, reporting, and further analysis. It should provide efficient mechanisms for data retrieval.
    \item \textbf{API Interface}: The system should provide a well-documented API interface to allow integration with external systems for configuration, monitoring, alert retrieval, and report generation.
    \item \textbf{Reporting}: The system should be capable of generating customizable reports summarizing detected anomalies, system performance, and market trends.
\end{itemize}

\subsection{Non-Functional Requirements}
Non-functional requirements define the quality attributes of the system. Key non-functional requirements for this project include:
\begin{itemize}
    \item \textbf{Performance}: The system must process data and detect anomalies with low latency, typically within sub-second timeframes, to be effective in real-time markets.
    \item \textbf{Scalability}: The system architecture must be scalable to handle increasing volumes of data, a growing number of monitored financial instruments, and an expanding user base without degradation in performance.
    \item \textbf{Reliability and Availability}: The system must be highly reliable and available, minimizing downtime to ensure continuous market surveillance. This includes fault tolerance and data redundancy.
    \item \textbf{Accuracy}: The anomaly detection algorithms must achieve a high level of accuracy, minimizing both false positives (incorrectly identifying normal behavior as anomalous) and false negatives (failing to detect actual anomalies).
    \item \textbf{Security}: The system must ensure the confidentiality, integrity, and availability of sensitive financial data. This includes secure data transmission, storage, and access controls.
    \item \textbf{Maintainability}: The system should be designed in a modular and well-documented manner to facilitate easy maintenance, updates, and future enhancements.
\end{itemize}


% \section{Adopted Methodology}

% The development of this financial surveillance system follows a structured approach that emphasizes iterative development, open-source technologies, and comprehensive testing:

% \subsection{Open-Source Technology Preference}

% Priority is given to open-source technologies to ensure cost-effectiveness, community support, and avoid vendor lock-in. The selected technology stack includes:
% \begin{itemize}
%     \item Apache Kafka for real-time data streaming
%     \item Elasticsearch for data storage and search
%     \item FastAPI for RESTful API development
%     \item Redis for caching and temporary data storage
%     \item Celery for asynchronous task processing
% \end{itemize}

% \subsection{Data-Driven Testing Strategy}

% The system is tested using both simulated and real financial data to ensure robustness and accuracy. Initial testing uses controlled, simulated datasets to validate core functionality, followed by testing with real market data to verify performance under actual conditions.

% \subsection{Microservices Architecture}

% The system is designed using a microservices architecture to ensure modularity, scalability, and maintainability. Each component has a specific responsibility and can be developed, tested, and deployed independently.

\section{Report Structure}

This report is organized into three main chapters, each focusing on a specific aspect of the project:
\begin{itemize}
    \item \textbf{Chapter 1} introduces the project, presenting the general context, problem statement, and requirements.
    
    \item \textbf{Chapter 2} describes the actual work, including the system design, architectural choices, implementation details, and the decisions made throughout the project.
    
    \item \textbf{Chapter 3} concludes the report, summarizing the main achievements, lessons learned, and providing perspectives for future development.
\end{itemize}
